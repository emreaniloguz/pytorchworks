{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:10<00:00, 93.31it/s] \n",
      "100%|██████████| 938/938 [00:09<00:00, 95.77it/s]\n",
      "100%|██████████| 938/938 [00:09<00:00, 98.69it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 98.21\n",
      "Accuracy on test set: 98.20\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision # torch package for vision related things\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn  # All neural network modules\n",
    "from torch.utils.data import DataLoader  # Gives easier dataset managment by creating mini batches etc.\n",
    "from tqdm import tqdm  # For nice progress bar!\n",
    "\n",
    "\n",
    "\n",
    "# Simple CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=8,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=8,\n",
    "            out_channels=16,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Hyperparameters\n",
    "in_channels = 1\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epochs = 3\n",
    "\n",
    "# Load Data\n",
    "train_dataset = datasets.MNIST(root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize network\n",
    "model = CNN(in_channels=in_channels, num_classes=num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train Network\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent or adam step\n",
    "        optimizer.step()\n",
    "\n",
    "# Check accuracy on training & test to see how good our model\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "\n",
    "    model.train()\n",
    "    return num_correct/num_samples\n",
    "\n",
    "\n",
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def predict_image(img, model):\n",
    "    xb = img.unsqueeze(0).to(device=device)\n",
    "    yb = model(xb).to(device=device)\n",
    "    _, preds = torch.max(yb, dim=1)\n",
    "    return preds[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicted: 4\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread(\"res.jpeg\",0)\n",
    "\n",
    "\n",
    "\n",
    "#img = cv2.resize(img,(28,28))\n",
    "\n",
    "_,img=cv2.threshold(img, 110,155,cv2.THRESH_BINARY_INV)\n",
    "kernel = np.ones((5,5),np.uint8)\n",
    "img = cv2.resize(img,(28,28))\n",
    "#img = cv2.dilate(img,kernel=kernel,iterations=1)\n",
    "cv2.imwrite(\"res_cnn.jpeg\",img)\n",
    "img=torch.Tensor(img)\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "#plt.imshow(img[0], cmap='gray')\n",
    "\n",
    "print(' predicted:', predict_image(img,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-q3d_8t8e\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-41b93320f9c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mlow_yellow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m49\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m49\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mup_yellow\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m74\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m160\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m213\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-q3d_8t8e\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    low_yellow = np.array([18,49,49])\n",
    "    up_yellow =  np.array([74,160,213])\n",
    "\n",
    "    mask = cv2.inRange(frame,low_yellow,up_yellow)\n",
    "\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if len(contours) != 0:\n",
    "        c = max(contours,key=cv2.contourArea)\n",
    "\n",
    "        M = cv2.moments(c)\n",
    "\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "        crop = frame[x:x+w+100,y:y+h+100,:]\n",
    "        \n",
    "        crop = cv2.cvtColor(crop,cv2.COLOR_BGR2GRAY)\n",
    "        _,crop = cv2.threshold(crop,87,255,cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "        img=torch.Tensor(crop)\n",
    "        img = img.unsqueeze(0)\n",
    "\n",
    "\n",
    "\n",
    "        print(' predicted:', predict_image(img,model))\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    \n",
    "    cv2.imshow(\"crop\",crop)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xff == ord('q'):\n",
    "        break\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# optional argument for trackbars\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "# named ites for easy reference\n",
    "barsWindow = 'Bars'\n",
    "hl = 'H Low'\n",
    "hh = 'H High'\n",
    "sl = 'S Low'\n",
    "sh = 'S High'\n",
    "vl = 'V Low'\n",
    "vh = 'V High'\n",
    "\n",
    "# set up for video capture on camera 0\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# create window for the slidebars\n",
    "cv.namedWindow(barsWindow, flags = cv.WINDOW_AUTOSIZE)\n",
    "\n",
    "# create the sliders\n",
    "cv.createTrackbar(hl, barsWindow, 0, 179, nothing)\n",
    "cv.createTrackbar(hh, barsWindow, 0, 179, nothing)\n",
    "cv.createTrackbar(sl, barsWindow, 0, 255, nothing)\n",
    "cv.createTrackbar(sh, barsWindow, 0, 255, nothing)\n",
    "cv.createTrackbar(vl, barsWindow, 0, 255, nothing)\n",
    "cv.createTrackbar(vh, barsWindow, 0, 255, nothing)\n",
    "\n",
    "# set initial values for sliders\n",
    "cv.setTrackbarPos(hl, barsWindow, 0)\n",
    "cv.setTrackbarPos(hh, barsWindow, 179)\n",
    "cv.setTrackbarPos(sl, barsWindow, 0)\n",
    "cv.setTrackbarPos(sh, barsWindow, 255)\n",
    "cv.setTrackbarPos(vl, barsWindow, 0)\n",
    "cv.setTrackbarPos(vh, barsWindow, 255)\n",
    "\n",
    "while(True):\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv.GaussianBlur(frame, (5, 5), 0)\n",
    "    \n",
    "    # convert to HSV from BGR\n",
    "    hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "\n",
    "    # read trackbar positions for all\n",
    "    hul = cv.getTrackbarPos(hl, barsWindow)\n",
    "    huh = cv.getTrackbarPos(hh, barsWindow)\n",
    "    sal = cv.getTrackbarPos(sl, barsWindow)\n",
    "    sah = cv.getTrackbarPos(sh, barsWindow)\n",
    "    val = cv.getTrackbarPos(vl, barsWindow)\n",
    "    vah = cv.getTrackbarPos(vh, barsWindow)\n",
    "\n",
    "    # make array for final values\n",
    "    HSVLOW = np.array([hul, sal, val])\n",
    "    HSVHIGH = np.array([huh, sah, vah])\n",
    "\n",
    "    # apply the range on a mask\n",
    "    mask = cv.inRange(hsv, HSVLOW, HSVHIGH)\n",
    "    maskedFrame = cv.bitwise_and(frame, frame, mask = mask)\n",
    "\n",
    "    # display the camera and masked images\n",
    "    cv.imshow('Masked', maskedFrame)\n",
    "    cv.imshow('Camera', frame)\n",
    "\n",
    "\t# check for q to quit program with 5ms delay\n",
    "    if cv.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# clean up our resources\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "75a30548fdf3dbc5d56c450174bec395510dfa79d754af80d480ee316ccf8c82"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
